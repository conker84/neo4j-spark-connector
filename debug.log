[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for neo4j-contrib:neo4j-connector-apache-spark_2.11_common:jar:4.0.0
[WARNING] 'artifactId' contains an expression but should be a constant. @ neo4j-contrib:neo4j-connector-apache-spark_${scala.binary.version}_common:4.0.0, /Users/andrea/IdeaProjects/neo4j-spark-connector/common/pom.xml, line 7, column 17
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for neo4j-contrib:neo4j-connector-apache-spark_2.11_test-support:jar:4.0.0
[WARNING] 'artifactId' contains an expression but should be a constant. @ neo4j-contrib:neo4j-connector-apache-spark_${scala.binary.version}_test-support:4.0.0, /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/pom.xml, line 7, column 17
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for neo4j-contrib:neo4j-connector-apache-spark_2.11_2.4:jar:4.0.0
[WARNING] 'artifactId' contains an expression but should be a constant. @ neo4j-contrib:neo4j-connector-apache-spark_${scala.binary.version}_2.4:4.0.0, /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/pom.xml, line 7, column 17
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] neo4j-connector-apache-spark                                       [pom]
[INFO] neo4j-connector-apache-spark-test-support                          [jar]
[INFO] neo4j-connector-apache-spark-common                                [jar]
[INFO] neo4j-connector-apache-spark-doc                                   [jar]
[INFO] neo4j-connector-apache-spark-2.4                                   [jar]
[INFO] 
[INFO] -------------< neo4j-contrib:neo4j-connector-apache-spark >-------------
[INFO] Building neo4j-connector-apache-spark 4.0.0                        [1/5]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ neo4j-connector-apache-spark ---
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:add-source (scala-compile) @ neo4j-connector-apache-spark ---
[INFO] Add Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/src/main/scala
[INFO] Add Test Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/src/test/scala
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:compile (scala-compile) @ neo4j-connector-apache-spark ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-compile) @ neo4j-connector-apache-spark ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-test-compile) @ neo4j-connector-apache-spark ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] ----< neo4j-contrib:neo4j-connector-apache-spark_2.11_test-support >----
[INFO] Building neo4j-connector-apache-spark-test-support 4.0.0           [2/5]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Deleting /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/target
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:add-source (scala-compile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Add Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/src/main/scala
[INFO] Add Test Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/src/test/scala
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:compile (scala-compile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 6 Scala sources and 1 Java source to /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/target/classes ...
[INFO] Done compiling.
[INFO] compile in 6.7 s
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-compile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 1 source file to /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/andrea/IdeaProjects/neo4j-spark-connector/test-support/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] No sources to compile
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-test-compile) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ neo4j-connector-apache-spark_2.11_test-support ---
[INFO] No tests to run.
[INFO] 
[INFO] -------< neo4j-contrib:neo4j-connector-apache-spark_2.11_common >-------
[INFO] Building neo4j-connector-apache-spark-common 4.0.0                 [3/5]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Deleting /Users/andrea/IdeaProjects/neo4j-spark-connector/common/target
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:add-source (scala-compile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Add Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/common/src/main/scala
[INFO] Add Test Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/common/src/test/scala
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:compile (scala-compile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 11 Scala sources to /Users/andrea/IdeaProjects/neo4j-spark-connector/common/target/classes ...
[WARNING] [Warn] /Users/andrea/IdeaProjects/neo4j-spark-connector/common/src/main/scala/org/neo4j/spark/service/SchemaService.scala:639: non-variable type argument String in type pattern java.util.Map[String,_] is unchecked since it is eliminated by erasure
[WARNING] [Warn] /Users/andrea/IdeaProjects/neo4j-spark-connector/common/src/main/scala/org/neo4j/spark/util/Neo4jUtil.scala:221: non-variable type argument String in type pattern scala.collection.immutable.Map[String,AnyRef] (the underlying of Map[String,AnyRef]) is unchecked since it is eliminated by erasure
[WARNING] two warnings found
[INFO] Done compiling.
[INFO] compile in 6.6 s
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-compile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 9 Scala sources to /Users/andrea/IdeaProjects/neo4j-spark-connector/common/target/test-classes ...
[WARNING] [Warn] : there was one deprecation warning; re-run with -deprecation for details
[WARNING] one warning found
[INFO] Done compiling.
[INFO] compile in 3.5 s
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Changes detected - recompiling the module!
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Changes detected - recompiling the module!
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-test-compile) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] compile in 0.2 s
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ neo4j-connector-apache-spark_2.11_common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.neo4j.spark.CommonTestSuiteWithApocIT
For test testGetSchemaFromNodeBoolean => connections are ok
For test testGetSchemaFromNodeString => connections are ok
For test testGetSchemaFromNodeLong => connections are ok
For test testGetSchemaFromNodeDouble => connections are ok
For test testGetSchemaFromNodePoint2D => connections are ok
For test testGetSchemaFromDate => connections are ok
For test testGetSchemaFromDateTime => connections are ok
For test testGetSchemaFromTime => connections are ok
For test testGetSchemaFromStringArray => connections are ok
For test testGetSchemaFromDateArray => connections are ok
For test testGetSchemaFromTimestampArray => connections are ok
For test testGetSchemaFromTimeArray => connections are ok
For test testGetSchemaFromIntegerArray => connections are ok
For test testGetSchemaFromMultipleNodes => connections are ok
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.947 s - in org.neo4j.spark.CommonTestSuiteWithApocIT
[INFO] Running org.neo4j.spark.util.Neo4jOptionsTest
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.023 s - in org.neo4j.spark.util.Neo4jOptionsTest
[INFO] Running org.neo4j.spark.util.Neo4jImplicitsTest
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 s - in org.neo4j.spark.util.Neo4jImplicitsTest
[INFO] Running org.neo4j.spark.util.Neo4jUtilTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in org.neo4j.spark.util.Neo4jUtilTest
[INFO] Running org.neo4j.spark.CommonTestSuiteIT
For test testGetSchemaFromNodeBoolean => connections are ok
For test testGetSchemaFromNodeString => connections are ok
For test testGetSchemaFromNodeLong => connections are ok
For test testGetSchemaFromNodeDouble => connections are ok
For test testGetSchemaFromNodePoint2D => connections are ok
For test testGetSchemaFromDate => connections are ok
For test testGetSchemaFromDateTime => connections are ok
For test testGetSchemaFromTime => connections are ok
For test testGetSchemaFromStringArray => connections are ok
For test testGetSchemaFromDateArray => connections are ok
For test testGetSchemaFromTimestampArray => connections are ok
For test testGetSchemaFromTimeArray => connections are ok
For test testGetSchemaFromIntegerArray => connections are ok
For test testGetSchemaFromMultipleNodes => connections are ok
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.718 s - in org.neo4j.spark.CommonTestSuiteIT
[INFO] Running org.neo4j.spark.service.Neo4jQueryServiceTest
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.074 s - in org.neo4j.spark.service.Neo4jQueryServiceTest
[INFO] Running org.neo4j.spark.service.AuthenticationTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.409 s - in org.neo4j.spark.service.AuthenticationTest
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 72, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------------< neo4j-contrib:neo4j-spark-connector-docs >--------------
[INFO] Building neo4j-connector-apache-spark-doc 4.0.0                    [4/5]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ neo4j-spark-connector-docs ---
[INFO] 
[INFO] --- build-helper-maven-plugin:3.0.0:parse-version (parse-version) @ neo4j-spark-connector-docs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ neo4j-spark-connector-docs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/andrea/IdeaProjects/neo4j-spark-connector/doc/src/main/resources
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:add-source (scala-compile) @ neo4j-spark-connector-docs ---
[INFO] Add Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/doc/src/main/scala
[INFO] Add Test Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/doc/src/test/scala
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:compile (scala-compile) @ neo4j-spark-connector-docs ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-compile) @ neo4j-spark-connector-docs ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ neo4j-spark-connector-docs ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ neo4j-spark-connector-docs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/andrea/IdeaProjects/neo4j-spark-connector/doc/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ neo4j-spark-connector-docs ---
[INFO] No sources to compile
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-test-compile) @ neo4j-spark-connector-docs ---
[INFO] compile in 0.0 s
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ neo4j-spark-connector-docs ---
[INFO] No tests to run.
[INFO] 
[INFO] --------< neo4j-contrib:neo4j-connector-apache-spark_2.11_2.4 >---------
[INFO] Building neo4j-connector-apache-spark-2.4 4.0.0                    [5/5]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Deleting /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/target
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:add-source (scala-compile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Add Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/src/main/scala
[INFO] Add Test Source directory: /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/src/test/scala
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:compile (scala-compile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 6 Scala sources to /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/target/classes ...
[INFO] Done compiling.
[INFO] compile in 2.8 s
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-compile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 12 Scala sources and 2 Java sources to /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/target/test-classes ...
[INFO] Done compiling.
[INFO] compile in 8.0 s
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Changes detected - recompiling the module!
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 2 source files to /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/target/test-classes
[INFO] 
[INFO] --- scala-maven-plugin:4.3.0:testCompile (scala-test-compile) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/andrea/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.11-1.3.1-bin_2.11.12__55.0-1.3.1_20191012T045515.jar
[INFO] Compiling 2 Java sources to /Users/andrea/IdeaProjects/neo4j-spark-connector/spark-2.4/target/test-classes ...
[INFO] Done compiling.
[INFO] compile in 0.4 s
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ neo4j-connector-apache-spark_2.11_2.4 ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.neo4j.spark.SparkConnectorSuiteIT
For test testReadNodeWithLocalDateTime => connections are ok
For test testReadNodeWithArrayDurations => connections are ok
For test testReadNodeWithPointArray => connections are ok
For test testReadNodeWithLongArray => connections are ok
For test testReadNodeWithGeoPointArray => connections are ok
For test testReadNodeWithPoint => connections are ok
For test testReadNodeWithGeoPoint => connections are ok
For test testReadNodeWithDate => connections are ok
For test testReadNodeWithLong => connections are ok
For test testReadNodeWithTime => connections are ok
For test testReadNodeWithLocalTimeArray => connections are ok
For test testReadNodeWithDuration => connections are ok
For test testReadNodeWithArrayZonedDateTime => connections are ok
For test testReadNodeWithDoubleArray => connections are ok
For test testReadNodeWithStringArray => connections are ok
For test testReadNodeWithZonedDateTime => connections are ok
For test testReadNodeWithBooleanArray => connections are ok
For test testReadNodeWithMap => connections are ok
For test testReadNodeWithDouble => connections are ok
For test testReadNodeWithArrayDate => connections are ok
For test testReadNodeWithPoint3DArray => connections are ok
For test testReadNodeWithPoint3D => connections are ok
For test testReadNodeWithLocalTime => connections are ok
For test testReadNodeWithString => connections are ok
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.661 s - in org.neo4j.spark.SparkConnectorSuiteIT
[INFO] Running org.neo4j.spark.SparkConnectorAuraTest
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.003 s - in org.neo4j.spark.SparkConnectorAuraTest
[INFO] Running org.neo4j.spark.SparkConnector24ScalaSuiteWithApocIT
For test testShouldReturnSamePropertiesForNodesWithMultipleLabels => connections are ok
For test testRelationshipsDifferentFieldValues => connections are ok
For test testReadNodeWithLocalDateTime => connections are ok
For test testReadNodeRepartition => connections are ok
For test testReadNodeWithArrayDurations => connections are ok
For test testReadNodeWithGteFilterWithProp => connections are ok
For test testReadNodeWithEqualToFilter => connections are ok
For test testReadRelsCustomPartitions => connections are ok
For test testReadNodeWithLteFilter => connections are ok
For test testReadNodeWithPointArray => connections are ok
For test testReadNodeWithLongArray => connections are ok
For test testRelationshipsFlatten => connections are ok
For test testReadNodeWithDifferentOperatorFilter => connections are ok
For test testReadNodeWithGeoPointArray => connections are ok
For test testReadNodeWithGteFilter => connections are ok
For test testReadNodeWithGtFilter => connections are ok
For test testReadNodeHasIdField => connections are ok
For test testReadNodeWithNotEqualToFilter => connections are ok
For test testReadNodeWithLtFilter => connections are ok
For test testReadNodeWithPoint => connections are ok
For test testReadNodeWithEndsWith => connections are ok
For test testReadNodesCustomPartitions => connections are ok
For test testReadNodeWithGeoPoint => connections are ok
For test testReadNodeWithDate => connections are ok
For test testReadNodeWithLong => connections are ok
For test testReadNodeWithTime => connections are ok
For test testReadNodeWithLocalTimeArray => connections are ok
For test testReadNodeWithStartsWith => connections are ok
For test testReadNodeWithAndCondition => connections are ok
For test testReadNodeWithDuration => connections are ok
For test testReadNodeWithArrayZonedDateTime => connections are ok
For test testReadNodeWithOrCondition => connections are ok
For test testReadNodeWithDoubleArray => connections are ok
For test testReturnProcedure => connections are ok
For test testReadNodeWithStringArray => connections are ok
For test testReadNodeWithZonedDateTime => connections are ok
For test testReadNodeWithBooleanArray => connections are ok
For test testRelFiltersWithoutMap => connections are ok
For test testShouldReturnSamePropertiesForNodesWithMultipleLabelsAndDifferentValues => connections are ok
For test testReadNodeHasUnusualLabelsField => connections are ok
For test testReadNodeWithIsNullFilter => connections are ok
For test testRelFiltersWithMap => connections are ok
For test testReadNodeWithIsNotNullFilter => connections are ok
For test testReadNodeHasLabelsField => connections are ok
For test testRelationshipsMap => connections are ok
For test testReadNodeWithDouble => connections are ok
For test testReadNodeWithArrayDate => connections are ok
For test testReadNodeWithInFilter => connections are ok
For test testReadNodeWithPoint3DArray => connections are ok
For test testReadNodeWithPoint3D => connections are ok
For test testReadNodeWithContains => connections are ok
For test testReadNodeWithLocalTime => connections are ok
For test testReadNodeWithFieldWithDifferentTypes => connections are ok
For test testReadNodeWithString => connections are ok
[WARNING] Tests run: 55, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 65.331 s - in org.neo4j.spark.SparkConnector24ScalaSuiteWithApocIT
[INFO] Running org.neo4j.spark.SparkConnector24ScalaSuiteIT
For test testThrowsExceptionOnWriteQuery => connections are ok
For test testRelationshipsDifferentFieldValues => connections are ok
For test testEmptyDataset => connections are ok
For test testReadNodeWithGtDateFilter => connections are ok
For test testReadNodeWithLocalDateTime => connections are ok
For test testReadNodeWithArrayDurations => connections are ok
For test testReadNodeWithGteFilterWithProp => connections are ok
For test testShouldSelectTheSystemColumnsInRelationship => connections are ok
For test testReadNodeWithEqualToFilter => connections are ok
For test testReadRelsCustomPartitions => connections are ok
For test testReadNodeWithLteFilter => connections are ok
For test testReadNodeWithPointArray => connections are ok
For test testReadNodeWithLongArray => connections are ok
For test testRelationshipsFlatten => connections are ok
For test testReadNodeWithDifferentOperatorFilter => connections are ok
For test testReadNodeWithGeoPointArray => connections are ok
For test testShouldReturnJustTheSelectedFieldWithQuery => connections are ok
For test testReadNodeWithGteFilter => connections are ok
For test testShouldFailWithExplicitErrorIfSkipLimitIsUsedAtTheEndOfTheQueryWithMultilineQuery => connections are ok
For test testShouldReturnJustTheSelectedFieldWithRelationship => connections are ok
For test testReadNodeWithGtFilter => connections are ok
For test testReadNodeHasIdField => connections are ok
For test testReadNodeWithNotEqualToFilter => connections are ok
For test testReadNodeWithLtFilter => connections are ok
For test testShouldReturnJustTheSelectedFieldWithNode => connections are ok
For test testShouldAllowSkipLimitInsideTheQuery => connections are ok
For test testReadNodeWithPoint => connections are ok
For test testReadRelationshipFilters => connections are ok
For test testShouldReturnJustTheSelectedFieldWithFilter => connections are ok
For test testReadNodeWithEndsWith => connections are ok
For test testReadNodesCustomPartitions => connections are ok
For test testReadNodeWithGeoPoint => connections are ok
For test testThrowsExceptionIfThreeValidReadOptionAreSet => connections are ok
For test testReadNodeWithDate => connections are ok
For test testReadNodeWithLong => connections are ok
For test testReadNodeWithTime => connections are ok
For test testReadNodeWithGtSpatialFilter => connections are ok
For test testReadNodeWithLocalTimeArray => connections are ok
For test testShouldReturnJustTheSelectedFieldWithRelationshipAndWeirdColumn => connections are ok
For test testQueries => connections are ok
For test testReadNodeWithStartsWith => connections are ok
For test testReadNodeWithAndCondition => connections are ok
For test testThrowsExceptionIfNoValidReadOptionIsSet => connections are ok
For test testReadNodeWithDuration => connections are ok
For test testReadNodeWithArrayZonedDateTime => connections are ok
For test testColumnSorted => connections are ok
For test testReadNodeWithOrCondition => connections are ok
For test testReadNodeWithDoubleArray => connections are ok
For test testComplexQuery => connections are ok
For test testReadNodeWithStringArray => connections are ok
For test testShouldFailWithExplicitErrorIfLowercaseSkipLimitIsUsedAtTheEndOfTheQuery => connections are ok
For test testShouldFailWithExplicitErrorIfSkipLimitIsUsedAtTheEndOfTheQuery => connections are ok
For test testShouldFailWithExplicitErrorIfRandomcaseSkipLimitIsUsedAtTheEndOfTheQuery => connections are ok
For test testReadNodeWithZonedDateTime => connections are ok
For test testReadNodeWithNotEqualToDateFilter => connections are ok
For test testReadNodeWithEqualToDateFilter => connections are ok
For test testReadQueryCustomPartitions => connections are ok
For test testReadNodeWithBooleanArray => connections are ok
For test testRelFiltersWithoutMap => connections are ok
For test testReadNodeHasUnusualLabelsField => connections are ok
For test testComplexReturnStatement => connections are ok
For test testShouldPassTheScriptResult => connections are ok
For test testShouldReturnJustTheSelectedFieldWithNodeAndWeirdColumnName => connections are ok
For test testShouldCreateTheCorrectDataframeWithTwoPartitions => connections are ok
For test testShouldReturnJustTheSelectedFieldWithRelationshipWithFilter => connections are ok
For test testReadNodeWithIsNullFilter => connections are ok
For test testRelFiltersWithMap => connections are ok
For test testReadNodeWithIsNotNullFilter => connections are ok
For test testReadNodeHasLabelsField => connections are ok
For test testRelationshipsMap => connections are ok
For test testReadNodeWithDouble => connections are ok
For test testReadNodeWithArrayDate => connections are ok
For test testReadNodeWithInFilter => connections are ok
For test testReadNodeWithPoint3DArray => connections are ok
For test testReadNodeWithPoint3D => connections are ok
For test testThrowsExceptionIfTwoValidReadOptionAreSet => connections are ok
For test testComplexReturnStatementNoValues => connections are ok
For test testReadNodeWithContains => connections are ok
For test testReadNodeWithLocalTime => connections are ok
For test testReadNodeWithFieldWithDifferentTypes => connections are ok
For test testReadNodeWithString => connections are ok
For test should$u0020throw$u0020an$u0020error$u0020because$u0020the$u0020node$u0020already$u0020exists => connections are ok
For test should$u0020work$u0020match$u0020source$u0020node$u0020and$u0020merge$u0020target$u0020node => connections are ok
For test should$u0020insert$u0020index$u0020while$u0020insert$u0020nodes => connections are ok
For test should$u0020handle$u0020unusual$u0020column$u0020names => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020map$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020relations$u0020with$u0020KEYS$u0020mode$u0020with$u0020props => connections are ok
For test should$u0020work$u0020create$u0020source$u0020node$u0020and$u0020match$u0020target$u0020node => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020point$minus3d$u0020array$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020date$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020nodes$u0020into$u0020Neo4j$u0020with$u0020points => connections are ok
For test should$u0020not$u0020create$u0020constraint$u0020when$u0020insert$u0020nodes$u0020because$u0020they$u0020already$u0020exist => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020point$minus3d$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020relations$u0020with$u0020KEYS$u0020mode => connections are ok
For test should$u0020throw$u0020an$u0020error$u0020because$u0020SaveMode$u002EOverwrite$u0020need$u0020node$u002Ekeys => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020timestamp$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020int$u0020array$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020duration$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020create$u0020constraint$u0020when$u0020insert$u0020nodes => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020int$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020within$u0020partitions => connections are ok
For test testThrowsExceptionIfThreeValidReadOptionAreSet => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020point$minus2d$u0020array$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020duration$u0020array$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020give$u0020error$u0020if$u0020native$u0020mode$u0020doesn$u0027t$u0020find$u0020a$u0020valid$u0020schema => connections are ok
For test testThrowsExceptionIfNoValidReadOptionIsSet => connections are ok
For test should$u0020write$u0020a$u0020custom$u0020map$u0020with$u0020query$u0020method => connections are ok
For test should$u0020skip$u0020null$u0020properties => connections are ok
For test should$u0020read$u0020and$u0020write$u0020relations$u0020with$u0020node$u0020overwrite$u0020mode => connections are ok
For test should$u0020throw$u0020an$u0020exception$u0020for$u0020a$u0020read$u0020only$u0020query => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020point$minus2d$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020update$u0020the$u0020node$u0020that$u0020already$u0020exists => connections are ok
For test testThrowsExceptionIfTwoValidReadOptionAreSet => connections are ok
For test should$u0020manage$u0020script$u0020passing$u0020the$u0020data$u0020to$u0020the$u0020executors => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020string$u0020array$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020insert$u0020data$u0020with$u0020a$u0020custom$u0020query => connections are ok
For test should$u0020write$u0020nodes$u0020with$u0020string$u0020values$u0020into$u0020Neo4j => connections are ok
For test should$u0020insert$u0020indexes$u0020while$u0020insert$u0020with$u0020query => connections are ok
For test testShouldThrowClearErrorIfADbIsSpecified => connections are ok
[WARNING] Tests run: 122, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 105.246 s - in org.neo4j.spark.SparkConnector24ScalaSuiteIT
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 202, Failures: 0, Errors: 0, Skipped: 5
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for neo4j-connector-apache-spark 4.0.0:
[INFO] 
[INFO] neo4j-connector-apache-spark ....................... SUCCESS [  1.682 s]
[INFO] neo4j-connector-apache-spark-test-support .......... SUCCESS [  7.456 s]
[INFO] neo4j-connector-apache-spark-common ................ SUCCESS [ 56.735 s]
[INFO] neo4j-connector-apache-spark-doc ................... SUCCESS [  0.280 s]
[INFO] neo4j-connector-apache-spark-2.4 ................... SUCCESS [03:39 min]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  04:46 min
[INFO] Finished at: 2021-02-27T01:00:54+01:00
[INFO] ------------------------------------------------------------------------
